{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms.functional as VF\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from hydra import initialize, compose\n",
    "\n",
    "from gazebot.test import make_gaze_agent\n",
    "from gazebot.utils import array2image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hydra initialize\n",
    "with initialize(version_base=None, config_path=\"../config\"):\n",
    "    args = compose(config_name=\"config.yaml\")\n",
    "    args.hydra_base_dir = os.getcwd()\n",
    "    args.device = args.cuda_device if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Set seeds\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(args.device)\n",
    "if device.type == \"cuda\" and torch.cuda.is_available() and args.cuda_deterministic:\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "torch.cuda.set_device(device)  # change default device (e.g. .cuda() or torch.cuda.IntTensor(x))\n",
    "\n",
    "print(OmegaConf.to_yaml(args))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load trained gaze model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model\n",
    "gaze_agent = make_gaze_agent(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load demonstration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = args.expert.test_path[0]\n",
    "data_files = sorted([os.path.join(os.path.expanduser(data_dir), f) for f in os.listdir(data_dir) if \"h5\" in f])\n",
    "print(data_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_gif = True\n",
    "\n",
    "data_scores = []\n",
    "for i in range(len(data_files)):\n",
    "    print(f\"Evaluation Demonstration ({i}): {data_files[i]}\")\n",
    "    images = []\n",
    "    scores = []\n",
    "    with h5py.File(data_files[i], \"r\") as e:\n",
    "        eps_steps = len(e[\"left_img\"])\n",
    "\n",
    "        # change_steps: steps in which gaze transition is occurred\n",
    "        change_steps = e[\"change_steps\"][1:]\n",
    "        print(\"change_steps:\", change_steps)\n",
    "\n",
    "        for step in range(eps_steps):\n",
    "            image = np.transpose(np.stack([e[\"left_img\"][step], e[\"right_img\"][step]]), (0, 3, 1, 2)) / 255.0  # (2, C, H, W)\n",
    "            if args.expert.bgr:\n",
    "                image = image[:, [2, 1, 0]]  # BGR2RGB\n",
    "\n",
    "            _, _, H, W = image.shape\n",
    "\n",
    "            # Gaze\n",
    "            human_gaze = np.array(e[\"gaze\"][step]).reshape(2, 2)  # teleoperator's gaze position in pixel coord\n",
    "            human_gaze = np.clip(human_gaze, [0, 0], [W - 1, H - 1])  # (2, 2)\n",
    "            human_gaze = np.round(human_gaze).astype(np.int64)  # (2, 2)\n",
    "\n",
    "            # SegIdx\n",
    "            seg_idx = np.sum(np.array(change_steps) <= step)\n",
    "\n",
    "            # To tensor\n",
    "            image = torch.as_tensor(image, dtype=torch.float, device=device)  # (2, C, H, W)\n",
    "            image = VF.normalize(image, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            image = image.unsqueeze(0)  # (1, 2, C, H, W)\n",
    "\n",
    "            seg_idx = torch.tensor([seg_idx], dtype=torch.long)  # (1,)\n",
    "            seg_idx = seg_idx.unsqueeze(0)  # (1, 1)\n",
    "\n",
    "            # Predict gaze\n",
    "            with torch.no_grad():\n",
    "                predict_gaze, _ = gaze_agent(image, seg_idx)  # (1, 2, 2)\n",
    "            predict_gaze = gaze_agent.model.denormalize(predict_gaze, H, W).detach().cpu().numpy()[0]  # (2, 2)\n",
    "            predict_gaze = np.round(predict_gaze).astype(np.int64)  # (2, 2)\n",
    "\n",
    "            score = np.linalg.norm(human_gaze - predict_gaze) / max(H, W)  # Normalize by longer edge length\n",
    "            scores.append(score)\n",
    "\n",
    "            # Visualize\n",
    "            if save_gif:\n",
    "                im = np.array(e[\"left_img\"][step])\n",
    "                if not args.expert.bgr:\n",
    "                    im = cv2.cvtColor(im, cv2.COLOR_RGB2BGR)  # RGB2BGR\n",
    "                im = cv2.circle(im, (human_gaze[0, 0], human_gaze[0, 1]), 20, (0, 0, 255), 5)\n",
    "                im = cv2.circle(im, (predict_gaze[0, 0], predict_gaze[0, 1]), 20, (255, 255, 255), 5)\n",
    "                images.append(array2image(im[:, :, [2, 1, 0]]).resize((320, 180)))\n",
    "\n",
    "    if save_gif:\n",
    "        os.makedirs(f\"outputs/{args.expert.task_type}\", exist_ok=True)\n",
    "        images[0].save(\n",
    "            f\"outputs/{args.expert.task_type}/gaze_{data_files[i]}.gif\",\n",
    "            save_all=True,\n",
    "            append_images=images[1:],\n",
    "            optimize=False,\n",
    "            duration=40,\n",
    "            loop=1,\n",
    "        )\n",
    "        print(f\"Save outputs/{args.expert.task_type}/gaze_{data_files[i]}.gif\")\n",
    "\n",
    "    data_scores.append(scores)\n",
    "    print(\"episode score:\", np.mean(scores))\n",
    "\n",
    "    plt.plot(scores, label=\"score\")\n",
    "    plt.show()\n",
    "\n",
    "print(\"Total score:\", np.mean(np.concatenate(data_scores)), np.median(np.concatenate(data_scores)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "localbc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
