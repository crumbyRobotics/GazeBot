{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms.functional as VF\n",
    "import hydra\n",
    "from omegaconf import OmegaConf\n",
    "import h5py\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from hydra import initialize, compose\n",
    "\n",
    "from gazebot.utils import array2image, pcd2image\n",
    "from gazebot.train import state_action_metrics, load_agent\n",
    "from gazebot.agent import create_manipulation_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hydra initialize\n",
    "with initialize(version_base=None, config_path=\"../config\"):\n",
    "    args = compose(config_name=\"config.yaml\")\n",
    "    args.hydra_base_dir = os.getcwd()\n",
    "    args.device = args.cuda_device if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "# Set seeds\n",
    "random.seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "torch.manual_seed(args.seed)\n",
    "\n",
    "# Set device\n",
    "device = torch.device(args.device)\n",
    "if device.type == \"cuda\" and torch.cuda.is_available() and args.cuda_deterministic:\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "torch.cuda.set_device(device)  # change default device (e.g. .cuda() or torch.cuda.IntTensor(x))\n",
    "\n",
    "print(OmegaConf.to_yaml(args))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Action Prediction Model (LocalBC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_mean, state_std, action_pose_mean, action_pose_std = state_action_metrics(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Use small transformer for localbc\n",
    "args.agent.enc_layers = 1\n",
    "args.agent.dec_layers = 1\n",
    "args.agent.dim_feedforward = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_manipulation_agent(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = hydra.utils.to_absolute_path(\"path/to/localbc/model/dir\") # NOTE Specify trained localbc path\n",
    "load_agent(agent, model_path, args, ignore_error=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Demo Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = [os.path.expanduser(d) for d in args.expert.train_path]\n",
    "data_files = sorted([os.path.join(d, f) for d in data_dir for f in os.listdir(d) if \"h5\" in f])\n",
    "\n",
    "data_idxs = []\n",
    "for eps_idx, episode_file in enumerate(data_files):\n",
    "    with h5py.File(episode_file, \"r\") as e:\n",
    "        if \"right_state\" not in e:\n",
    "            break\n",
    "        eps_steps = len(e[\"right_state\"])\n",
    "        if eps_steps < 2:\n",
    "            break\n",
    "\n",
    "        # change_steps: steps in which gaze transition is occurred\n",
    "        if \"change_steps\" in e:\n",
    "            change_steps = list(e[\"change_steps\"][1:])\n",
    "            # NOTE Remove gaze transition after the task is completed\n",
    "            if len(change_steps) == args.expert.num_sub_task + 1:\n",
    "                change_steps = change_steps[:-1]\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        # episodeをchange_stepで分割\n",
    "        init_step = 0\n",
    "        for sub_task_idx, change_step in enumerate(change_steps):\n",
    "            # Add data to dataset\n",
    "            data_idx = {\"file\": episode_file, \"init_step\": init_step, \"change_step\": change_step, \"sub_task_idx\": sub_task_idx}\n",
    "            data_idxs.append(data_idx)\n",
    "            init_step = change_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(action):\n",
    "    assert action.shape[-1] == len(action_pose_mean) == len(action_pose_std)\n",
    "    return action * torch.tensor(action_pose_std, dtype=action.dtype, device=action.device) + torch.tensor(\n",
    "        action_pose_mean, dtype=action.dtype, device=action.device\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Visualize bottleneck step & localbc loss\n",
    "- You can visualize before saving localbc loss by save_localbc_loss.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = args.env.image_dim[::-1][:-1]\n",
    "\n",
    "LOSS_WEIGHTS = [5.0, 5.0, 5.0, 1.0, 1.0, 1.0, 0]  # 0.005]\n",
    "\n",
    "data_localbc_losses = [[] for _ in range(args.expert.num_sub_task)]\n",
    "for i, data_idx in enumerate(data_idxs):\n",
    "    print(f\"\\n\\nLoad episode {i}: {data_idx['file']}\\n\")\n",
    "\n",
    "    with h5py.File(data_idx[\"file\"], \"r\") as e:\n",
    "        eps_steps = len(e[\"left_f_state\"])\n",
    "\n",
    "        init_step = int(data_idx[\"init_step\"])\n",
    "        change_step = int(data_idx[\"change_step\"])\n",
    "        sub_task_idx = int(data_idx[\"sub_task_idx\"])\n",
    "        print(\"init_step, change_step:\", init_step, change_step)\n",
    "\n",
    "        # Action\n",
    "        action_left_arm = np.array(e[\"left_f_state\"][init_step + 1 : change_step, :6])  # (N, ARM_DOF)\n",
    "        action_left_gripper = np.array(\n",
    "            e[\"left_f_hstate\"][init_step : change_step - 1, [6]]\n",
    "        )  # (N, GRIPPER_DOF), Use hstate as action for pseudo force control of the gripper\n",
    "        action_right_arm = np.array(e[\"right_f_state\"][init_step + 1 : change_step, :6])  # (N, ARM_DOF)\n",
    "        action_right_gripper = np.array(\n",
    "            e[\"right_f_hstate\"][init_step : change_step - 1, [6]]\n",
    "        )  # (N, GRIPPER_DOF), Use hstate as action for pseudo force control of the gripper\n",
    "        action_seq = np.concatenate((action_left_arm, action_left_gripper, action_right_arm, action_right_gripper), axis=1)  # (N, state_dim)\n",
    "\n",
    "        localbc_losses = []\n",
    "        action_norms = []\n",
    "        pcds = []\n",
    "        for step in range(init_step, change_step - 1):\n",
    "            ### Measure bottleneck score of sampled bottleneck step ###\n",
    "            # Obs\n",
    "            obs = {}\n",
    "            obs[\"state\"] = np.concatenate([e[\"left_f_state\"][step], e[\"right_f_state\"][step]], axis=0)  # (state_dim,)\n",
    "            obs[\"state\"] = (obs[\"state\"] - state_mean) / state_std\n",
    "            obs[\"image\"] = np.transpose(np.array(e[\"left_img\"][step]), (2, 0, 1)) / 255.0  # [0, 1], (C, H, W)\n",
    "            obs[\"depth\"] = np.transpose(e[\"depth_img\"][step], (2, 0, 1)).astype(np.float32)  # mm, [0, inf), (1, H, W)\n",
    "\n",
    "            if args.expert.bgr:\n",
    "                obs[\"image\"] = np.ascontiguousarray(obs[\"image\"][[2, 1, 0]])  # BGR2RGB\n",
    "\n",
    "            obs[\"state\"] = torch.as_tensor(obs[\"state\"], dtype=torch.float, device=device)\n",
    "            obs[\"image\"] = torch.as_tensor(obs[\"image\"], dtype=torch.float, device=device)\n",
    "            obs[\"image\"] = VF.normalize(obs[\"image\"], mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            if obs[\"image\"].shape[1:] != torch.Size(image_size[::-1]):\n",
    "                obs[\"image\"] = VF.resize(obs[\"image\"], size=image_size[::-1])\n",
    "            obs[\"depth\"] = torch.as_tensor(obs[\"depth\"], dtype=torch.float, device=device)\n",
    "            if obs[\"depth\"].shape[1:] != torch.Size(image_size[::-1]):\n",
    "                obs[\"depth\"] = VF.resize(obs[\"depth\"], size=image_size[::-1])\n",
    "\n",
    "            # Gaze\n",
    "            gaze = np.array(e[\"gaze\"][step])  # (N, 4), [W, H]\n",
    "            gaze = np.clip(gaze, [0, 0, 0, 0], [image_size[0] - 1, image_size[1] - 1, image_size[0] - 1, image_size[1] - 1])\n",
    "\n",
    "            gaze = torch.as_tensor(gaze, dtype=torch.long, device=device)\n",
    "\n",
    "            # Batch\n",
    "            obs[\"state\"] = obs[\"state\"].unsqueeze(0)\n",
    "            obs[\"image\"] = obs[\"image\"].unsqueeze(0)\n",
    "            obs[\"depth\"] = obs[\"depth\"].unsqueeze(0)\n",
    "            gaze = gaze.unsqueeze(0)\n",
    "\n",
    "            step = step - init_step\n",
    "\n",
    "            # LocalBC\n",
    "            with torch.no_grad():\n",
    "                action_hat, pcd = agent.local_bc(obs, gaze, is_inference=True)\n",
    "\n",
    "            measure_action_length = 10  # Step\n",
    "\n",
    "            action = action_seq[step : step + measure_action_length]  # (Ntraj, state_dim)\n",
    "            action_hat = denormalize(action_hat)[0].detach().cpu().numpy()[: len(action)]  # (Ntraj, state_dim)\n",
    "\n",
    "            # action prediction loss\n",
    "            left_loss_action = np.average((action_hat[0, :7] - action[0, :7]) ** 2, weights=np.array(LOSS_WEIGHTS) ** 2)\n",
    "            right_loss_action = np.average((action_hat[0, 7:] - action[0, 7:]) ** 2, weights=np.array(LOSS_WEIGHTS) ** 2)\n",
    "            \n",
    "            # action norm\n",
    "            left_action_norm = np.linalg.norm(np.array(e[\"left_f_state\"][step + 1]) - np.array(e[\"left_f_state\"][step]))\n",
    "            right_action_norm = np.linalg.norm(np.array(e[\"right_f_state\"][step + 1]) - np.array(e[\"right_f_state\"][step]))\n",
    "\n",
    "            # Log history for visualize\n",
    "            localbc_losses.append([left_loss_action, right_loss_action])\n",
    "            action_norms.append([left_action_norm, right_action_norm])\n",
    "            pcds.append(pcd[0])\n",
    "\n",
    "        localbc_losses = np.array(localbc_losses)\n",
    "        action_norms = np.array(action_norms)\n",
    "\n",
    "        # Filter\n",
    "        filtered_localbc_losses = np.array(\n",
    "            [np.mean(localbc_losses[max(0, i - 4) : min(i + 5, len(localbc_losses))], axis=0) for i in range(len(localbc_losses))]\n",
    "        )\n",
    "\n",
    "        # normalize scale\n",
    "        normalized_localbc_losses = localbc_losses * 1 / np.median(filtered_localbc_losses, axis=0)\n",
    "        normalized_filtered_localbc_losses = filtered_localbc_losses * 1 / np.median(filtered_localbc_losses, axis=0)\n",
    "\n",
    "        # LR for each subtask\n",
    "        LR = [0, 0]  # NOTE Specify this\n",
    "\n",
    "        # Detect bottleneck\n",
    "        THRESH = 1.0\n",
    "        MINIMUM_STEPS = int((change_step - init_step) * 0.35)\n",
    "        bottleneck_step_lr = []\n",
    "        for _lr in range(2):\n",
    "            bottleneck_step = init_step + 1\n",
    "            max_score = -np.inf\n",
    "            for _step in range(init_step + 1, change_step - 2):\n",
    "                score = np.sum(normalized_filtered_localbc_losses[: _step - init_step, _lr] > THRESH) + np.sum(\n",
    "                    normalized_filtered_localbc_losses[_step - init_step :, _lr] < THRESH\n",
    "                )\n",
    "                if score > max_score:\n",
    "                    max_score = score\n",
    "                    bottleneck_step = _step\n",
    "            if change_step - bottleneck_step < MINIMUM_STEPS:\n",
    "                bottleneck_step = init_step + 1\n",
    "            bottleneck_step_lr.append(bottleneck_step)\n",
    "\n",
    "        if LR[sub_task_idx] == 0:\n",
    "            # (Left)\n",
    "            plt.plot(normalized_localbc_losses[:, 0], label=\"localbc\")\n",
    "            plt.plot(normalized_filtered_localbc_losses[:, 0], label=\"filtered\")\n",
    "            plt.legend()\n",
    "            plt.hlines([THRESH], xmin=0, xmax=len(localbc_losses), colors=\"black\")\n",
    "            plt.vlines([bottleneck_step_lr[0] - init_step], ymin=-10, ymax=10, colors=\"red\")\n",
    "            plt.ylim(0, 3)\n",
    "            plt.show()\n",
    "\n",
    "            # (Left)\n",
    "            plt.plot(action_norms[:, 0], label=\"action norm\")\n",
    "            plt.legend()\n",
    "            # plt.hlines([THRESH], xmin=0, xmax=len(action_norms), colors=\"black\")\n",
    "            plt.vlines([bottleneck_step_lr[0] - init_step], ymin=-10, ymax=10, colors=\"red\")\n",
    "            plt.ylim(0, 3)\n",
    "            plt.show()\n",
    "\n",
    "            image = np.array(e[\"left_img\"][bottleneck_step_lr[0]])\n",
    "            if args.expert.bgr:\n",
    "                image = np.ascontiguousarray(image[:, :, [2, 1, 0]])  # BGR2RGB\n",
    "            predict_gaze = np.array(e[\"gaze\"][bottleneck_step_lr[0]])[:2]  # np.array(e[\"predict_gaze\"][bottleneck_step_lr[0]])[:2]  # (2,)\n",
    "            image = cv2.circle(image, (int(predict_gaze[0]), int(predict_gaze[1])), 20, (255, 255, 255), 5)\n",
    "            display(array2image(image).resize((320, 180)))\n",
    "\n",
    "            display(pcd2image(pcds[bottleneck_step_lr[0] - init_step]))\n",
    "\n",
    "        else:\n",
    "            # (Right)\n",
    "            plt.plot(normalized_localbc_losses[:, 1], label=\"localbc\")\n",
    "            plt.plot(normalized_filtered_localbc_losses[:, 1], label=\"filtered\")\n",
    "            plt.legend()\n",
    "            plt.hlines([THRESH], xmin=0, xmax=len(localbc_losses), colors=\"black\")\n",
    "            plt.vlines([bottleneck_step_lr[1] - init_step], ymin=-10, ymax=10, colors=\"red\")\n",
    "            plt.ylim(0, 3)\n",
    "            plt.show()\n",
    "\n",
    "            image = np.array(e[\"left_img\"][bottleneck_step_lr[1]])\n",
    "            if args.expert.bgr:\n",
    "                image = np.ascontiguousarray(image[:, :, [2, 1, 0]])  # BGR2RGB\n",
    "            predict_gaze = np.array(e[\"gaze\"][bottleneck_step_lr[1]])[:2]  # np.array(e[\"predict_gaze\"][bottleneck_step_lr[0]])[:2]  # (2,)\n",
    "            image = cv2.circle(image, (int(predict_gaze[0]), int(predict_gaze[1])), 20, (255, 255, 255), 5)\n",
    "            display(array2image(image).resize((320, 180)))\n",
    "\n",
    "            display(pcd2image(pcds[bottleneck_step_lr[1] - init_step]))\n",
    "\n",
    "        print(\"bottleneck_step_lr:\", bottleneck_step_lr)\n",
    "\n",
    "        plt.clf()\n",
    "        plt.close()\n",
    "\n",
    "        data_localbc_losses[sub_task_idx].append(filtered_localbc_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Visualize bottleneck step & localbc loss\n",
    "- This is faster if you already saved localbc_loss by save_localbc_loss.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = args.env.image_dim[::-1][:-1]\n",
    "\n",
    "for i, data_idx in enumerate(data_idxs):\n",
    "    if i > 50:\n",
    "        break\n",
    "\n",
    "    print(f\"\\n\\nLoad episode {i}: {data_idx['file']}\\n\")\n",
    "    with h5py.File(data_idx[\"file\"], \"r\") as e:\n",
    "        eps_steps = len(e[\"left_f_state\"])\n",
    "\n",
    "        init_step = data_idx[\"init_step\"]\n",
    "        change_step = data_idx[\"change_step\"]\n",
    "        sub_task_idx = data_idx[\"sub_task_idx\"]\n",
    "        print(\"sub_task_idx:\", sub_task_idx, \", init_step, change_step:\", init_step, change_step)\n",
    "\n",
    "        if \"localbc_loss\" not in e:\n",
    "            continue\n",
    "\n",
    "        # Detect bottleneck\n",
    "        THRESH = 1.0\n",
    "        MINIMUM_STEPS = int((change_step - init_step) * 0.35)  # 25\n",
    "        bottleneck_step_lr = []\n",
    "        for _lr in range(2):\n",
    "            localbc_loss = np.array(e[\"localbc_loss\"][init_step:change_step, _lr])\n",
    "            # Filter\n",
    "            filtered_localbc_loss = np.array([np.mean(localbc_loss[max(0, i - 4) : min(i + 5, len(localbc_loss))]) for i in range(len(localbc_loss))])\n",
    "            # normalize scale\n",
    "            normalized_localbc_loss = localbc_loss * 1 / np.median(filtered_localbc_loss)\n",
    "            normalized_filtered_localbc_loss = filtered_localbc_loss * 1 / np.median(filtered_localbc_loss)\n",
    "\n",
    "            # Bottleneck Detection \n",
    "            bottleneck_step = init_step + 1\n",
    "            max_score = -np.inf\n",
    "            for _step in range(init_step + 1, change_step - 2):\n",
    "                score = np.sum(normalized_filtered_localbc_loss[: _step - init_step] > THRESH) + np.sum(\n",
    "                    normalized_filtered_localbc_loss[_step - init_step :] < THRESH\n",
    "                )\n",
    "                if score > max_score:\n",
    "                    max_score = score\n",
    "                    bottleneck_step = _step\n",
    "            if change_step - bottleneck_step < MINIMUM_STEPS:\n",
    "                bottleneck_step = init_step + 1\n",
    "            bottleneck_step_lr.append(bottleneck_step)\n",
    "\n",
    "            # NOTE Specify this\n",
    "            LR = [0, 0]\n",
    "            if _lr == LR[sub_task_idx]:\n",
    "                # Pcd\n",
    "                obs = {}\n",
    "                state = np.concatenate([e[\"left_f_state\"][bottleneck_step], e[\"right_f_state\"][bottleneck_step]], axis=0)  # (state_dim,)\n",
    "                image = np.array(e[\"left_img\"][bottleneck_step])\n",
    "                depth = np.array(e[\"depth_img\"][bottleneck_step][:, :, 0])  # mm, [0, inf)\n",
    "\n",
    "                if args.expert.bgr:\n",
    "                    image = np.ascontiguousarray(image[:, :, [2, 1, 0]])  # BGR2RGB\n",
    "\n",
    "                gaze = np.array(e[\"gaze\"][bottleneck_step])  # np.array(e[\"predict_gaze\"][bottleneck_step])  # (4,), [W, H]\n",
    "                gaze = np.clip(gaze, [0, 0, 0, 0], [image_size[0] - 1, image_size[1] - 1, image_size[0] - 1, image_size[1] - 1])\n",
    "\n",
    "                # Visualize\n",
    "                plt.plot(normalized_localbc_loss, label=\"raw\")\n",
    "                plt.plot(normalized_filtered_localbc_loss, label=\"filtered\")\n",
    "                plt.hlines([THRESH], xmin=0, xmax=len(localbc_loss), colors=\"black\")\n",
    "                # plt.hlines([np.median(localbc_loss) * 1 / np.median(filtered_localbc_loss)], xmin=0, xmax=len(localbc_loss), colors=\"green\")\n",
    "                plt.ylim(0, 3)\n",
    "                plt.vlines([bottleneck_step - init_step], ymin=-10, ymax=10, colors=\"red\")\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "\n",
    "                print(\"bottleneck_step:\", bottleneck_step - init_step)\n",
    "\n",
    "                image = np.array(e[\"left_img\"][bottleneck_step])\n",
    "                if args.expert.bgr:\n",
    "                    image = np.ascontiguousarray(image[:, :, [2, 1, 0]])  # BGR2RGB\n",
    "                predict_gaze = np.array(e[\"predict_gaze\"][bottleneck_step])[:2]  # (2,)\n",
    "                image = cv2.circle(image, (predict_gaze[0], predict_gaze[1]), 20, (255, 255, 255), 5)\n",
    "                display(array2image(image).resize((320, 180)))\n",
    "\n",
    "                plt.clf()\n",
    "                plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "localbc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
